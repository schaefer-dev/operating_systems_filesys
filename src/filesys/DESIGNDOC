             +-------------------------+
             |            OS           |
             | PROJECT 4: FILE SYSTEMS |
             |     DESIGN DOCUMENT     |
             +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Daniel Schaefer <s9dlscae@stud.uni-saarland.de>
Christian Bohnenberger <s9cnbohn@stud.uni-saarland.de>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

             INDEXED AND EXTENSIBLE FILES
             ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

in inode.h:

/* number of direct/indirect/double-indirect blocks */
#define NUMBER_DIRECT_BLOCKS 118
#define NUMBER_INDIRECT_BLOCKS 1
#define NUMBER_DOUBLE_INDIRECT_BLOCKS 1

- These defines are used to define the number of direct and indirect blocks.

#define NUMBER_UNUSED_BYTES 
(128 - 8 - NUMBER_DIRECT_BLOCKS - NUMBER_INDIRECT_BLOCKS
 - NUMBER_DOUBLE_INDIRECT_BLOCKS)

- Computes the number of unused bytes in disk_inode to avoid manual 
recomputation in case of changing the number of direct or indirect blocks.

/* overall number of pointers in inode */
#define NUMBER_INODE_POINTERS (NUMBER_DIRECT_BLOCKS
 + NUMBER_INDIRECT_BLOCKS + NUMBER_DOUBLE_INDIRECT_BLOCKS)

/* number of pointers contained in a indirect block */
#define NUMBER_INDIRECT_POINTERS 128

#define DIRECT_BLOCKS_END (NUMBER_DIRECT_BLOCKS * BLOCK_SECTOR_SIZE)
- Defines the end of direct blocks in bytes.

#define MAX_FILESIZE ((NUMBER_DIRECT_BLOCKS + NUMBER_INDIRECT_BLOCKS *
 NUMBER_INDIRECT_POINTERS + NUMBER_DOUBLE_INDIRECT_BLOCKS *
 NUMBER_INDIRECT_POINTERS * NUMBER_INDIRECT_POINTERS) * BLOCK_SECTOR_SIZE)

- Automatically changes the maximal file length in bytes if the number of
direct or indirect pointers is changed.

#define INDIRECT_BLOCKS_END ((NUMBER_DIRECT_BLOCKS + NUMBER_INDIRECT_BLOCKS 
* NUMBER_INDIRECT_POINTERS) * BLOCK_SECTOR_SIZE)

- Computes automatically the end of indirect blocks in bytes. The computation
is based on the number of direct and indirect blocks.

#define DOUBLE_INDIRECT_BLOCKS_END ((NUMBER_DIRECT_BLOCKS + 
 NUMBER_INDIRECT_BLOCKS * NUMBER_INDIRECT_POINTERS +
 NUMBER_DOUBLE_INDIRECT_BLOCKS * NUMBER_INDIRECT_POINTERS 
 * NUMBER_INDIRECT_POINTERS) * BLOCK_SECTOR_SIZE)

- Defines the end of double indirect blocks in bytes.


/* struct which describes indirect_block which contains NUMBER_INDIRECT_POINTERS
   amount of pointers */
struct indirect_block
  {
    block_sector_t block_pointers[NUMBER_INDIRECT_POINTERS];
  };

/* On-disk inode.
   Must be exactly BLOCK_SECTOR_SIZE bytes long. */
struct inode_disk
 {
    off_t length;                       /* File size in bytes. */
    unsigned magic;                     /* Magic number. */
    bool directory;                     /* indicates if inode is a directory*/
    block_sector_t parent;              /* block sector of parent */
    unsigned index_level;               /* level 0 -> direct, 1->indirect,
                                           2->double-indirect */
    off_t current_index;                /* stores current index */
    off_t indirect_index;               /* indirect index */
    off_t double_indirect_index;        /* double indirect index */
    uint32_t unused[NUMBER_UNUSED_BYTES];                /* not used */
    /* pointers to blocks with file content: */
    block_sector_t direct_pointers[NUMBER_DIRECT_BLOCKS];               
    block_sector_t indirect_pointers[NUMBER_INDIRECT_BLOCKS];               
    block_sector_t double_indirect_pointers[NUMBER_DOUBLE_INDIRECT_BLOCKS];               
  };


/* In-memory inode. */
struct inode 
  {
    struct list_elem elem;              /* Element in inode list. */
    block_sector_t sector;              /* Sector number of disk location. */
    int open_cnt;                       /* Number of openers. */
    bool removed;                       /* True if deleted, false otherwise. */
    int deny_write_cnt;                 /* 0: writes ok, >0: deny writes. */
    off_t data_length;                  /* length of the file in bytes */
    off_t reader_length;                /* length of the file in bytes */
    bool directory;                     /* indicates if inode is a directory*/
    block_sector_t parent;              /* block sector of parent */

    /* stores index structure information */
    unsigned index_level;               /* level 0 -> direct, 1->indirect,
     2->double-indirect */
    off_t current_index;
    off_t indirect_index;
    off_t double_indirect_index;

    struct lock inode_extend_lock;      /* synchronises extension of file */
    struct lock inode_directory_lock;   /* lock to synchronise removing and
                                            adding of directories */
    struct lock inode_field_lock;       /* synchronies metadata */

    /* pointers to blocks with file content: */
    block_sector_t direct_pointers[NUMBER_DIRECT_BLOCKS];               
    block_sector_t indirect_pointers[NUMBER_INDIRECT_BLOCKS];               
    block_sector_t double_indirect_pointers[NUMBER_DOUBLE_INDIRECT_BLOCKS];              
  };

Explanations: 
1.) struct indirect blocks: struct which describes indirect_block which 
contains NUMBER_INDIRECT_POINTER amount of pointers

2.) struct inode disk: describes an on-disk inode.
Fiels in struct:
- off_t length: indicates the file size in bytes
- unsigned magic: magic number
- bool directory: boolean which stores if the inode is handled as normal file
or a directory (true if inode is directory)
- block_sector_t parent: stores the block_sector of the parent to open the
parent directory (only used if inode is directory)
- unsigned index_level: stores the current index level; 0 indicates direct 
blocks; 1 means indirect blocks; 2 means double indirect blocks
- off_t current_index: saves the next free index on the top-level layer
(direct block index, or the position in the indirect block array)
- off_t indirect_index: current offest within a indirect or the number of the
current indirect block in double indexed block
- off_t double_indirect_index: current index in the last in case of double
indirect blocks (only used for double indirect blocks)
- uint32_t unused[NUMBER_UNUSED_BYTES]: used to page-aligne the inode_disk
struct
- block_sector_t direct_pointers[NUMBER_DIRECT_BLOCKS]: array which stores
all direct pointer of length NUMBER_DIRECT_BLOCKS
- block_sector_t indirect_pointers[NUMBER_INDIRECT_BLOCKS]: array which stores
the indirect block pointers of length NUMBER_INDIRECT_BLOCKS
- block_sector_t double_indirect_pointers[NUMBER_DOUBLE_INDIRECT_BLOCKS]:
array which stores the double indirect block pointers of length
NUMBER_DOUBLE_INDIRECT_BLOCKS

3.) struct inode: structure to store inodes
Fields:
similar to disk_inode however without unused bytes but with some locks to
ensure secure synchronisation:
- struct lock inode_extend_lock: synchronises extension of file and ensures
that only one file can grow at a time
- struct lock inode_directory_lock: lock to synchronise removing and 
adding of directories to prevent adding 2 directories at a time etc.
- struct lock inode_field_lock: synchronies metadata to ensure consistency
of the inode metadata

- off_t data_length: indicates the length of a file in bytes this is set
during a write which needs a file extension to ensure save reads and file
extension
- off_t reader_length: length of the file in bytes only visible for readers
to prevent reading wrong bytes during a file extension


>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.

The maximum filesize is:
Filesize contained in Direct Blocks:                    118 * 512 = 60,416
Filesize contained in indirect Blocks:                  128 * 512 = 65,536
Filesize contained in doubly indirect Blocks:  128 * 128 * 512 = 8,388,608
--------------------------------------------------------------------------
Overall filesize:                                                8,514,560

8.120117188 Mebibyte (1024 byte = 1KB)
8.51456 Megabyte (1000 byte = 1KB)


---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.

This would happen if two processes enter inode_write_at at the same
time and try to write after EOF.
If both these files write into the same file they would try to extend
the same inode at the same time, but this is not possible beacuse:
- Before checking the condition if the write causes the inode to grow
  we acquire the inode_field_lock. Only one of these 2 processes will
  be able to acquire this lock and then notice that a grow has to be
  performed.
- Before releasing the inode_field_lock (which would allow
  the other process to check the grow condition) we acquire the
  inode_extend_lock. This lock will be held until the entire grow
  process is performed (includes writing the content to the block),
  which means that it is impossible for the other process to acquire it
  to perform another grow while the the first process is still working on
  the write after EOF.
- After the process is finished with that, the second process will
  acquire the extend lock and verify again if it the file still has to
  grow (this is very important because the grow performed by the first
  process might be already sufficient for the second process).
- If the condition to grow still holds, it executes grow (from the new EOF
  which was set by the previous grow and adds the still needed blocks) 
  and continues writing after EOF like the first process did.
  If it doesn't have to grow anymore it releases the inode_extend_lock right
  away and continues like a normal writer would. 

>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.

Readers and writers see different lengths during a file extension process.
This means that the reader_length of an inode is incremented only AFTER
a writer after EOF has completely finished while the data_length is
increased immediatly (data_length is e.g. used for further write processes).
This means that A will not be able to read after EOF until B has
finished its growing and writing after EOF completely.
If B has finished writing it is oubviously impossible for A to read
something B has not written.

>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.

Our implementation allows for full interleaving between all readers/writers
except for 1 special case: File extension, which was explained in the
question above. Generally the only case in which somebody has to wait is
the following:
1) Writers writing after EOF have to wait until the writer who extends the
   inode to the neccessary length for its write has finished growing the inode
   and writing his data after EOF.

Additionally as explained in A4 Readers can only read/see data after EOF
when the write which caused the inode extension has fully completed.

---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?

To support files of at least 8 Megabytes, we had to introduce at least
1 doubly indirect pointer. After achieving the minimum required maximum
filesize we decided, that we would like to optimize our access times of
small files as much as possible. This meant that we wanted to use as many
direct blocks as possible. The number we ended up with is
- 118 direct blocks
- 1 indirect block
- 1 doubly indirect block
We know that inode structures in memory now take up more space, but
we think that this is "worth it" considering the fact that DISK I/O is
usually the biggest bottleneck in modern systems, and physical memory
usually does not run out nowadays (especially considering that our
implementation is supposed to run with paging enabled).
Our solution uses the physical space given by a block the most "optimally"
in terms of containing the most actual file data with the least amount of
DISK I/O neccessary to obtain it.



                SUBDIRECTORIES
                ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

in inode.h:

As already mentioned there are some changes in inode and inode_disk
to differ between normal files and directories.
In particular:
- bool directory: boolean which stores if the inode is handled as normal file
or a directory (true if inode is directory)
- block_sector_t parent: stores the block_sector of the parent to open the
parent directory (only used if inode is directory)

- struct lock inode_directory_lock: lock to synchronise removing and 
adding of directories to prevent adding 2 directories at a time etc.


in thread.h:
/* Struct to save open files of a thread in a linked list */
struct file_entry
  {
    struct file *file;
    struct dir *dir;
    int fd;
    struct list_elem elem; 
  };
- A file_entry now also contains a struct dir entry to differ between open
files and open directories.


in struct thread added:

/* stores the current working directory of the process */
- struct dir *current_working_dir

Current_working_dir stores the current working directory of the
process which is initially either the parent working directory or the
root directory.


---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

We have a seperate parsing function 'parse_string_to_path_file' which
parses a string and returns the path and the file_name as seperate 'strings'.
Here we catch cases like multiple consecutive "/" etc.

To get from a path 'string' to a opened directory struct, we use the function
'dir_open_path'. Its starts with the special case of the string being empty.
In this case we return the cwd directory of the thread (or NULL if it has
been removed already, special case!)

If the length is >0 we check if the first character is a '/' or not. If
it is, we start our "iteration" using the root directory, otherwise we start
it with the CWD of the running thread (again, if it has not been removed yet!)

Now we use strtok with the token '/' to iterate over all directory names
contained in the path. In each of these iterations we check first if the
token is '..', in which case we set the directory to the parent of the
directory. If the token is '.' we just continue with the next token.
For all other cases we start a lookup in the directory of the iteration
and look for the token string. If it is contained (and a directory +
not removed) we switch directory to this newly found directory.
This iteration over tokens continues until we either find a "invalid"
(not directory, not found in directory, already marked as removed) token
or until we iterated over all tokens successfully.

If we iterated over all tokens successfully, we simply return the directory
we ended up with (which has been opened already).

For all invalid cases we simply return NULL.


---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

A directory is stored in an inode with the boolean 'directory' set.
The inode has a lock called inode_directory_lock.
Assume two processes try to remove a single file in the same directory:
- before dir_remove verifies, that the remove file exists and actually
  removes it, it has to acquire the inode_directory_lock from the directory
  it is trying to delete in. Holding the lock ensures that no creating
  or removing actions is occuring in the same directory at the same time.
  This means that the second process has to wait until the first process
  releases the lock - which it only does after the removal is completely
  finished.
  When the second process finally acquires the lock, it will first check
  if the file with "name" is contained in the directory (using lookup).
  This will not be the case anymore because the first process already
  removed it entirely. The lock essentially makes the lookup and removal
  atomic.

The procedure of creating a file inside a directory works exactly the
same way, the lock is only released after creation is completely finished
-> no races possible, because lookup + creation atomic

The synchronization mentioned above also makes sure that removal + creation
of files in the same directory don't happen at the same time, because
this special case also introduces data races.


>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

Our implementation allows to remove a open directory even if it is
in use as process's current working directory, however this is only
possible if the directory is empty. To check if the directory is empty
we use a function which checks if there are no entries or all entries
are not in use.
Once a directory is removed the inode is set to removed.
When the process with the removed current working directory now opens an
absolute path it is okay as long as the path doesn't contain any deleted
directory. This is checked in "open_path" which checks the validity of every
directory mentioned in the absolute path and returns NULL if a single
directory in the path is either not found or marked as removed.
If the process tries to open or work on a relative path its corresponding
directory inode (which is received by its current working directory) is
checked for validity. This means we check if the removed flag in the inode
is set and if this is the case the action which used the relative path fails.

---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

The current working directory is a refernce of type dir contained in
every thread. The dir contains a reference to the inode, which contains
the directory data. It makes sense to save it in thread, mainly because
you can easily set it in thread_create (to the parents directory, if it
exists, NULL otherwise). This is important because the root directory does
not exist yet, for the first thread which is being created. It's the
easiest location to access the parent directory, which starts the thread
using the exec syscall.
Also this makes it very convenient to reopen the current working directory
in thread_create and to close it again in process_exit (because only processes
can have current working directories). This way we don't have to work
on inodes, but can instead use functions which handle just directories,
which is a nice abstraction.

                 BUFFER CACHE
                 ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

in cache.h:
/* defines the maximal number of cache entries */
#define CACHE_SIZE 64

/* write back every second */
#define WRITE_BACK_INTERVAL 1000

/* lock to lock the complete cache used e.g. to ensure that create is
atomic and the is no race to set the next free cache*/
struct lock filesys_cache_lock;

/* used to ensure that only 1 thread at a time can evict a page */
struct lock filesys_cache_evict_lock;

struct cache_block {
  /* METADATA */
  /* inidicates if the cache block is accessed */
  bool accessed;
  /* inidicates if the cache block is dirty (used for write behind) */ 
  bool dirty;
  /* counts how often the page is accessed increment on every read, write and
  access */ 
  int accessed_counter;

  /* indicates if a reader or writer is currently using the block and how many;
  increment at start of read/write and decrement on exit of read/write */
  int read_writer_working;

  /* lock used to lock metadata updates */
  struct lock cache_field_lock;

  /* Cached content + disk sector */
  uint8_t cached_content[BLOCK_SECTOR_SIZE];
  block_sector_t disk_sector;
};

/* structure(array) to store cache blocks */
struct cache_block *cache_array[CACHE_SIZE];

/* indicates the next free block in the cache */
int next_free_cache;

/* points to the block which is next considered in clock algorithm during
eviction */
int next_evict_cache;

in cache.c:

/* defines the maximal number of pages which can be inserted in read ahead
queue */
#define MAX_READ_AHEAD_SIZE 32

/* lock to synchronise updates of read ahead queue size */
struct lock read_ahead_lock;

/* list to store the next sectors to prefetch in cache */
struct list read_ahead_queue;

/* semaphore to indicate if there are still elements in the
read ahead queue; used to synchronise insert and pop */
struct semaphore read_ahead_semaphore;

/* stores the number of elements in the read ahead queue */
int read_ahead_queue_size;

/* defines a read ahead entry which entails the block sector
which should be prefetched and list_elem to store them in the list */
struct read_ahead_entry {
  block_sector_t disk_sector;
  struct list_elem elem;
};

---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

We use an algorithm similar to the clock algorithm, that means we always
store the place we evicted in the last eviction and restart from this point
on. However, there is a difference to the clock algorithm. We use an
accessed counter which is incremented every time the cache block is accessed
by a read or write operation.
This counter is decremented every time the eviction algorithm accesses the
cache block and we evict a cache block if the accessed counter is 0.
This helps to keep blocks which are often accessed in the recent past in the 
cache and prefers to evict cache blocks which are rarely accessed.
To check and modify the access counter we first acquire the cache_field_lock
of the particular cache block and ensure correct synchronisation because
another process could change the counter if the lock is not held.
Futhermore, we check if the read_writer_working variable is 0 because
otherwise we cannot evict this block (more detailed description how the
read_writer_working variable works in C5).
If all the preconditions for eviction (accessed_counter and read_writer_working
are 0) we check if the block is dirty and write the content back to the disk
if necessary.
We ensure that the filesys_cache_evict_lock is hold to ensure that only one
process can evict a cache block at a time. Furthermore the filesys_cache_lock
which ensures that the global metadata are correctly set (e.g. next_free_cache)
and the allocation of a cache block can be done atomically has to be hold
since eviction performs a cache allocation in some sense.

>> C3: Describe your implementation of write-behind.
In the initialization function of our cache we start a thread which
runs in a while true loop and is woken up every WRITE_BACK_INTERVAL ms.
If the thread is woken up it starts to iterate over all elements in our
cache array (starting on the last index which is still contains an cache
entry).
During the iteration the function and acquires the cache_field_lock of
the cache anc checks the dirty bit. If the dirty bit of this cache entry
is set the function writes the block back to the disk and sets the dirty
bit to false and releases the cache_field_lock.
After iteratting over all elements the thread sleeps WRITE_BACK_INTERVAL
ms and starts again writing back the dirty entries to the disk (as 
already described).

>> C4: Describe your implementation of read-ahead.
We use a read_ahead_queue which is actually a double linked list
which allows us to push_back entries and pop at the front. 
This is important because we want to support a FIFO order.
Futhermore we use read_ahead_semaphore this a semaphore which 
is initially set to 0 and incremented every times an element is
added to the read_ahead_queue and decremented every times every
times an element is poped from the list (later on it will be
explained why this is important).
In the initialization function of our cache we start a thread which
runs in a while true loop and which calls sema_down on read_ahead_semaphore.
The semaphore is used to ensure that the thread doesn't wait busy and
it can only proceed if there is an element in the queue.
If this was succesful the read_ahead_lock is acquired and the next
read_ahead_entry, which contains the the block sector which should be
prefetched is contained, using pop front. Afterwards the read_ahead_lock
is released and the block sector is prefetched to a cache block using
filesys_cache_access which simply loads the contens from disk to the cache
(if not already contained in cache).
It is important to acquire to the read_ahead_lock to ensure that it is
impossible that the read_ahead thread pops an element from the list
and onther process adds an element at the same time.
Furthermore the lock ensures that only one process can add an element
to the list at a time.
Every read and write operation adds the next block_sector to the
read_ahead_queue by first checking if the block is within the block
size of the fs_device and afterwards acquiring the read_ahead_lock
to safely adding the read_ahead_entry with the corresponding
block sector to the read_ahead_queue.

Furthermore, we check the current length of the read_ahead_queue
and we deny further insertions if the length is already half of the
cache size because in this case the thread cannot prefetch all the
needed elements fast enough to the cache and read ahead could
potentially worse the performance since it replaces cache entries
(which are potentially needed by some processes) with some old
block sectors which are no longer needed (because they are added
too long ago to the read_ahead_queue).

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?

Every times a process performs a read or write on a cache block the 
read_writer_counter is incremented and decrement if the read/write
process is finished.
That means we use the read_writer_counter similar to the pin variable
of project 3. But there is a minor difference whereas pinning was just
a boolean variable read_writer_counter is counter because many processes
can access (read or write) a cache block at the same time and only if
no process is currently accessing the block the block is safe to be
evicted.
The variable read_writer_counter is locked by the cache_field_lock 
every time it is modified or read.
The eviction process checks the read_writer_counter before a block
is evited and only if the read_writer_counter is 0 the block will
be evicted.

>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

In the evict process, we iterate over all the array of cache entries.
Before we decide to evict a block, we first acquire the cache_field_lock
for this specific cache entry. Afterwards we verify that read_writer_counter
equals to zero. This can not be the case if any process is currently
reading or writing or trying to read or write this cache entry because
on entry in reading/writing the cache_field_lock is always acquired first
and the read_writer_counter incremented by one, which is only decremented
again if the writing/reading has been finished. This means that during an
evict no new reader can entry, because it can not acquire the cache_field_lock
and also no reader or writer can currently work on this cache entry because
in that case read_writer_counter would have to be greater than zero. The
cache_field_lock is held until the cache entry was completely evicted and
replaced by its new entry.

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

Likely to benefit from buffer caching in general:
Any workload which often accesses a specific part of storage will profit
heavily because the often accessed blocks will stay in cache, which will
siginificantly reduce the access time. For example a small executable which
is used by multiple processes and does not perform lots of I/O will stay
in cache and will not be loaded from disk all the time.

Read Ahead:
Reading or writing a larger file sequentially is improved significantly
by read-ahead. The reason why this is the case, is because the next block
we try to read/write is already asynchroniously loaded into cache. So the
process doesn't have to wait for the DISK I/O to complete.

Write Behind:
Assume a scenarion in which we rarely write in a file. Periodic writeback
asynchroniously writes these changes back to disk and in the case of an
eviction, the process evicting this cache block does not have write back
to disk again which speeds up the eviction process a lot.
Also write behind is very advantageous if you have a workload in which you
very frequently write to a file. The file will stay in cache and "accumalate"
the writes and not query a DISK I/O on every single small write. This reduces
the bottleneck of the I/O access a lot, because the changes are only written
back asynchroniously during a periodic writeback (which happens farely rarely)
or during eviction.
We trade a lot of small writes to very few bigger writes, which is a lot
faster mainly because of access/seek times.

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?
